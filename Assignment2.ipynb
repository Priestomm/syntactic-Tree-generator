{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "from nltk.tree import TreePrettyPrinter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree generator function\n",
    "\n",
    "This function parse the sentence given in input and add a prodcution in the grammar for each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree(text, grammar, nlp):\n",
    "    \"\"\"\n",
    "    Generate the syntax tree for a specific text\n",
    "    Arguments:\n",
    "        text: a list containing a sentence or a text in general\n",
    "        grammar: a string that represents the grammar that we will use\n",
    "        nlp: an object of type spacy used for POS tagging\n",
    "    Returns:\n",
    "        The syntax tree in a string format\n",
    "    \"\"\"\n",
    "    for sent in text:\n",
    "        print(sent)\n",
    "        \n",
    "        parsed_sent = nlp(sent)\n",
    "        prod = {}\n",
    "\n",
    "        for token in parsed_sent:\n",
    "            if token.pos_ not in prod.keys():\n",
    "                prod.update({token.pos_ : []})\n",
    "            prod[token.pos_].append(f\"'{token.text}'\")\n",
    "\n",
    "        for pos, word in prod.items():\n",
    "            grammar += f\"{pos} -> {' | '.join(word)}\\n\"\n",
    "        \n",
    "        print(grammar)\n",
    "        \n",
    "        nltk_grammar = nltk.CFG.fromstring(grammar)\n",
    "        parser = nltk.ChartParser(nltk_grammar)\n",
    "        words = nltk.word_tokenize(text[0])\n",
    "        trees = list(parser.parse(words))\n",
    "        \n",
    "        return(TreePrettyPrinter(trees[0]).text())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammars\n",
    "I defined two different grammars, one for Italian and French and one for German and English.\n",
    "\n",
    "The rules are the same specified in the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammarItFr = \"\"\"\n",
    "S ->  NP VP OBJ S | \n",
    "NP -> DET NOUN ADJ | DET NOUN | PROPN | PRON\n",
    "VP -> VERB | VERB ADV | AUX ADV | AUX\n",
    "OBJ -> PUNCT | NP PUNCT \n",
    "\"\"\" \n",
    "\n",
    "grammarDeEn = \"\"\"\n",
    "S ->  NP VP OBJ S | \n",
    "NP -> DET ADJ NOUN | DET NOUN | PROPN | PRON\n",
    "VP -> VERB | VERB ADV | AUX ADV | AUX\n",
    "OBJ -> PUNCT | NP PUNCT \n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Italian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il gatto mangia il pesce.\n",
      "\n",
      "S ->  NP VP OBJ S | \n",
      "NP -> DET NOUN ADJ | DET NOUN | PROPN | PRON\n",
      "VP -> VERB | VERB ADV | AUX ADV | AUX\n",
      "OBJ -> PUNCT | NP PUNCT \n",
      "DET -> 'Il' | 'il'\n",
      "NOUN -> 'gatto' | 'pesce'\n",
      "VERB -> 'mangia'\n",
      "PUNCT -> '.'\n",
      "\n",
      "                      S                     \n",
      "      ________________|___________________   \n",
      "     |          |             OBJ         | \n",
      "     |          |          ____|_____     |  \n",
      "     NP         VP        NP         |    | \n",
      "  ___|____      |      ___|____      |    |  \n",
      "DET      NOUN  VERB  DET      NOUN PUNCT  S \n",
      " |        |     |     |        |     |    |  \n",
      " Il     gatto mangia  il     pesce   .   ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"it_core_news_sm\") \n",
    "text = [ \"Il gatto mangia il pesce.\" ]\n",
    "\n",
    "print(tree(text, grammarItFr, nlp))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I attend the university.\n",
      "\n",
      "S ->  NP VP OBJ S | \n",
      "NP -> DET ADJ NOUN | DET NOUN | PROPN | PRON\n",
      "VP -> VERB | VERB ADV | AUX ADV | AUX\n",
      "OBJ -> PUNCT | NP PUNCT \n",
      "PRON -> 'I'\n",
      "VERB -> 'attend'\n",
      "DET -> 'the'\n",
      "NOUN -> 'university'\n",
      "PUNCT -> '.'\n",
      "\n",
      "             S                          \n",
      "  ___________|________________________   \n",
      " |     |               OBJ            | \n",
      " |     |          ______|________     |  \n",
      " NP    VP        NP              |    | \n",
      " |     |      ___|______         |    |  \n",
      "PRON  VERB  DET        NOUN    PUNCT  S \n",
      " |     |     |          |        |    |  \n",
      " I   attend the     university   .   ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "text = [\"I attend the university.\"]\n",
    "\n",
    "print(tree(text, grammarDeEn, nlp))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le cuisinier prépare le dîner.\n",
      "\n",
      "S ->  NP VP OBJ S | \n",
      "NP -> DET NOUN ADJ | DET NOUN | PROPN | PRON\n",
      "VP -> VERB | VERB ADV | AUX ADV | AUX\n",
      "OBJ -> PUNCT | NP PUNCT \n",
      "DET -> 'Le' | 'le'\n",
      "NOUN -> 'cuisinier' | 'dîner'\n",
      "VERB -> 'prépare'\n",
      "PUNCT -> '.'\n",
      "\n",
      "                           S                     \n",
      "      _____________________|___________________   \n",
      "     |               |             OBJ         | \n",
      "     |               |          ____|_____     |  \n",
      "     NP              VP        NP         |    | \n",
      "  ___|______         |      ___|____      |    |  \n",
      "DET        NOUN     VERB  DET      NOUN PUNCT  S \n",
      " |          |        |     |        |     |    |  \n",
      " Le     cuisinier prépare  le     dîner   .   ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"fr_core_news_sm\") \n",
    "text = [\"Le cuisinier prépare le dîner.\"]\n",
    "\n",
    "print(tree(text, grammarItFr, nlp))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            S                \n",
      "  __________|______________   \n",
      " |     |        OBJ        | \n",
      " |     |     ____|____     |  \n",
      " NP    VP   NP        |    | \n",
      " |     |    |         |    |  \n",
      "PRON  VERB PRON     PUNCT  S \n",
      " |     |    |         |    |  \n",
      "Ich  liebe dich       .   ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"de_core_news_sm\") \n",
    "text = [\"Ich liebe dich.\"]\n",
    "\n",
    "print(tree(text, grammarDeEn, nlp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "naturalLanguageP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "524c3cce6d6b4f7dd39c407e02a4597f84720b608390096e8a6f1d819f4c4c0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
